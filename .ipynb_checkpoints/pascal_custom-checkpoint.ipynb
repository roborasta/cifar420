{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from PIL import ImageDraw, ImageFont\n",
    "from matplotlib import patches, patheffects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object detection\n",
    "\n",
    "We want to do Object detection with bounding boxes using the Pascal VOC dataset\n",
    "\n",
    "to download the 2007 VOC dataset:\n",
    "\n",
    "wget http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/pascal/VOCdevkit'),\n",
       " PosixPath('data/pascal/pascal_train2007.json'),\n",
       " PosixPath('data/pascal/pascal_test2007.json'),\n",
       " PosixPath('data/pascal/pascal_val2012.json'),\n",
       " PosixPath('data/pascal/VOCtrainval_06-Nov-2007.tar'),\n",
       " PosixPath('data/pascal/pascal_val2007.json'),\n",
       " PosixPath('data/pascal/pascal_train2012.json'),\n",
       " PosixPath('data/pascal/models'),\n",
       " PosixPath('data/pascal/src'),\n",
       " PosixPath('data/pascal/tmp')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we're using pathlib from python 3 to manage paths\n",
    "# PATH gives us object oriented access to directories and files\n",
    "PATH = Path('data/pascal')\n",
    "\n",
    "# iterate through all the elements in the directory specified by PATH\n",
    "list(PATH.iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as the images, there are also annotations - bounding boxes showing where each object is. These were hand labeled. The original version were in XML, which is a little hard to work with nowadays, so we uses the more recent JSON version which you can download from this link:\n",
    "\n",
    "wget https://storage.googleapis.com/coco-dataset/external/PASCAL_VOC.zip\n",
    "\n",
    "You can see here how pathlib includes the ability to open files (amongst many other capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMAGES_BASIC_INFO is a python list containing one or more IMAGE_BASIC_INFO.\n",
    "\n",
    "Contains some basic information about all the images.\n",
    "\n",
    "*********\n",
    "\n",
    "IMAGE_BASIC_INFO is a python dictionary\n",
    "\n",
    "Contains the following basic info about one particular image:\n",
    "\n",
    "'file_name': A string, the image's name\n",
    "\n",
    "'width': A number, the image's width\n",
    "\n",
    "'height': A number, the image's height\n",
    "\n",
    "'id': A number, the image's id\n",
    "\n",
    "**********\n",
    "\n",
    "IMAGES_ANNOTATIONS is a python list containing one or more IMAGE_ANNOTATION.\n",
    "\n",
    "Contains info about all the bounding boxes inside the images.\n",
    "\n",
    "*********\n",
    "\n",
    "IMAGE_ANNOTATION is a python dictionary\n",
    "\n",
    "Contains the following information about one particular annotation in an image:\n",
    "\n",
    "'area': A number, the area of the annotation\n",
    "\n",
    "'bbox': A list containing [x, y, width, height], \n",
    "        x (column) and y (row), \n",
    "        are the xy coordinates of the top left corner,\n",
    "        width and height are the width and height of the annotation.\n",
    "        \n",
    "'category_id': A number, used to find the corresponding IMAGE_CATEGORY\n",
    "\n",
    "'id': A number\n",
    "\n",
    "'ignore': A number\n",
    "\n",
    "'image_id': A number, used to find the corresponding IMAGE_BASIC_INFO\n",
    "\n",
    "'iscrowd': A number\n",
    "\n",
    "'segmentation': A list\n",
    "\n",
    "********************\n",
    "\n",
    "IMAGES_CATEGORIES is a python list containing one or more IMAGE_CATEGORY.\n",
    "\n",
    "Contains the data describing all the different image categories that can be detected.\n",
    "\n",
    "**************\n",
    "\n",
    "IMAGE_CATEGORY is a python dictionary\n",
    "\n",
    "Contains the following information about one particular image category\n",
    "\n",
    "'id': A number\n",
    "\n",
    "'name': A string, the name of the category\n",
    "\n",
    "'supercategory': A string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path towards the JSON annotations\n",
    "json_annotations = PATH/'pascal_train2007.json'\n",
    "\n",
    "# the JSON annotations turned into a python dictionary\n",
    "trn_j = json.load(json_annotations.open())\n",
    "\n",
    "# displays the keys inside this dict\n",
    "# there should be 'images', 'type', 'annotations', 'categories'\n",
    "trn_j.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES, ANNOTATIONS, CATEGORIES = ['images', 'annotations', 'categories']\n",
    "\n",
    "# the 'images' key contains a IMAGES_BASIC_INFO data structure\n",
    "# let's see a sample of that\n",
    "IMAGES_BASIC_INFO_SAMPLE = trn_j[IMAGES][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 'annotations' key contains a IMAGES_ANNOTATIONS data structure\n",
    "# let's see a sample of that\n",
    "IMAGES_ANNOTATIONS_SAMPLE = trn_j[ANNOTATIONS][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 'categories' key contains a IMAGES_CATEGORIES data structure\n",
    "# let's see a sample of that\n",
    "IMAGES_CATEGORIES_SAMPLE = trn_j[CATEGORIES][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME, ID, IMG_ID, CAT_ID, BBOX = 'file_name', 'id', 'image_id', 'category_id', 'bbox'\n",
    "\n",
    "# let's create a category_id => category_name dictionary from the IMAGES_CATEGORIES data\n",
    "cats = dict((o[ID], o['name']) for o in trn_j[CATEGORIES])\n",
    "\n",
    "# let's then create a image_id => image_name \n",
    "# dictionary from the IMAGES_BASIC_INFO data structure\n",
    "trn_fns = dict((o[ID], o[FILE_NAME]) for o in trn_j[IMAGES])\n",
    "\n",
    "# let's also make a list of all the images id's\n",
    "trn_ids = [o[ID] for o in trn_j[IMAGES]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
