{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from PIL import ImageDraw, ImageFont\n",
    "from matplotlib import patches, patheffects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object detection\n",
    "\n",
    "We want to do Object detection with bounding boxes using the Pascal VOC dataset\n",
    "\n",
    "to download the 2007 VOC dataset:\n",
    "\n",
    "wget http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/pascal/VOCdevkit'),\n",
       " PosixPath('data/pascal/pascal_train2007.json'),\n",
       " PosixPath('data/pascal/pascal_test2007.json'),\n",
       " PosixPath('data/pascal/pascal_val2012.json'),\n",
       " PosixPath('data/pascal/VOCtrainval_06-Nov-2007.tar'),\n",
       " PosixPath('data/pascal/pascal_val2007.json'),\n",
       " PosixPath('data/pascal/pascal_train2012.json'),\n",
       " PosixPath('data/pascal/models'),\n",
       " PosixPath('data/pascal/src'),\n",
       " PosixPath('data/pascal/tmp')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we're using pathlib from python 3 to manage paths\n",
    "# PATH gives us object oriented access to directories and files\n",
    "PATH = Path('data/pascal')\n",
    "\n",
    "# iterate through all the elements in the directory specified by PATH\n",
    "list(PATH.iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as the images, there are also annotations - bounding boxes showing where each object is. These were hand labeled. The original version were in XML, which is a little hard to work with nowadays, so we uses the more recent JSON version which you can download from this link:\n",
    "\n",
    "wget https://storage.googleapis.com/coco-dataset/external/PASCAL_VOC.zip\n",
    "\n",
    "You can see here how pathlib includes the ability to open files (amongst many other capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMAGES_BASIC_INFO is a python list containing one or more IMAGE_BASIC_INFO.\n",
    "\n",
    "Contains some basic information about all the images.\n",
    "\n",
    "*********\n",
    "\n",
    "IMAGE_BASIC_INFO is a python dictionary\n",
    "\n",
    "Contains the following basic info about one particular image:\n",
    "\n",
    "'file_name': A string, the image's name\n",
    "\n",
    "'width': A number, the image's width\n",
    "\n",
    "'height': A number, the image's height\n",
    "\n",
    "'id': A number, the image's id\n",
    "\n",
    "**********\n",
    "\n",
    "IMAGES_ANNOTATIONS is a python list containing one or more IMAGE_ANNOTATION.\n",
    "\n",
    "Contains info about all the bounding boxes inside the images.\n",
    "\n",
    "*********\n",
    "\n",
    "IMAGE_ANNOTATION is a python dictionary\n",
    "\n",
    "Contains the following information about one particular annotation in an image:\n",
    "\n",
    "'area': A number, the area of the annotation\n",
    "\n",
    "'bbox': A list containing [x, y, width, height], \n",
    "        x (column) and y (row), \n",
    "        are the xy coordinates of the top left corner,\n",
    "        width and height are the width and height of the annotation.\n",
    "        \n",
    "'category_id': A number, used to find the corresponding IMAGE_CATEGORY\n",
    "\n",
    "'id': A number\n",
    "\n",
    "'ignore': A number, if 0, we don't ignore, if 1, we ignore\n",
    "\n",
    "'image_id': A number, used to find the corresponding IMAGE_BASIC_INFO\n",
    "\n",
    "'iscrowd': A number\n",
    "\n",
    "'segmentation': A list\n",
    "\n",
    "********************\n",
    "\n",
    "IMAGES_CATEGORIES is a python list containing one or more IMAGE_CATEGORY.\n",
    "\n",
    "Contains the data describing all the different image categories that can be detected.\n",
    "\n",
    "**************\n",
    "\n",
    "IMAGE_CATEGORY is a python dictionary\n",
    "\n",
    "Contains the following information about one particular image category\n",
    "\n",
    "'id': A number\n",
    "\n",
    "'name': A string, the name of the category\n",
    "\n",
    "'supercategory': A string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path towards the JSON annotations\n",
    "json_annotations = PATH/'pascal_train2007.json'\n",
    "\n",
    "# the JSON annotations turned into a python dictionary\n",
    "trn_j = json.load(json_annotations.open())\n",
    "\n",
    "# displays the keys inside this dict\n",
    "# there should be 'images', 'type', 'annotations', 'categories'\n",
    "trn_j.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES, ANNOTATIONS, CATEGORIES = ['images', 'annotations', 'categories']\n",
    "\n",
    "# the 'images' key contains a IMAGES_BASIC_INFO data structure\n",
    "# let's see a sample of that\n",
    "IMAGES_BASIC_INFO = trn_j[IMAGES]\n",
    "\n",
    "#IMAGES_BASIC_INFO_SAMPLE = trn_j[IMAGES][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 'annotations' key contains a IMAGES_ANNOTATIONS data structure\n",
    "# let's see a sample of that\n",
    "IMAGES_ANNOTATIONS = trn_j[ANNOTATIONS]\n",
    "\n",
    "#IMAGES_ANNOTATIONS_SAMPLE = trn_j[ANNOTATIONS][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 'categories' key contains a IMAGES_CATEGORIES data structure\n",
    "# let's see a sample of that\n",
    "IMAGES_CATEGORIES = trn_j[CATEGORIES]\n",
    "\n",
    "#IMAGES_CATEGORIES_SAMPLE = trn_j[CATEGORIES][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME, ID, IMG_ID, CAT_ID, BBOX = 'file_name', 'id', 'image_id', 'category_id', 'bbox'\n",
    "\n",
    "# let's create a category_id => category_name dictionary from the IMAGES_CATEGORIES data\n",
    "cats = dict((o[ID], o['name']) for o in IMAGES_CATEGORIES)\n",
    "\n",
    "# let's then create a image_id => image_name \n",
    "# dictionary from the IMAGES_BASIC_INFO data structure\n",
    "trn_fns = dict((o[ID], o[FILE_NAME]) for o in IMAGES_BASIC_INFO)\n",
    "trn_j[IMAGES]\n",
    "# let's also make a list of all the images id's\n",
    "trn_ids = [o[ID] for o in IMAGES_BASIC_INFO]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Okay so now let's look at the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path leading to our beloved images\n",
    "JPEGS = 'VOCdevkit/VOC2007/JPEGImages'\n",
    "IMG_PATH = PATH/JPEGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'collections' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-92bb6981a726>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrn_anno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mtrn_anno\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_key_annotation_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-92bb6981a726>\u001b[0m in \u001b[0;36mcreate_key_annotation_dict\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# To create such a \"default\" item, it calls the function object that you pass in the constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# inour case, the default item's value is an empty list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mtrn_anno\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# iterate through the IMAGES_ANNOTATIONS data structure...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'collections' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "INPUTS:\n",
    "\n",
    "-\n",
    "\n",
    "OUTPUT:\n",
    "\n",
    "- A python Dictionary\n",
    "\n",
    "Creates a dictionary where \n",
    "each key is an image id, \n",
    "and \n",
    "each key's value is a list of annotations for that image.\n",
    "each annotation is a\n",
    "([ymin, xmin, ymax, xmax], category_id) tuple.\n",
    "\"\"\"\n",
    "def create_key_annotation_dict():\n",
    "    # Usually, a Python dictionary throws a KeyError \n",
    "    # if you try to get an item with a key that is not currently \n",
    "    # in the dictionary. The defaultdict in contrast will simply create \n",
    "    # any items that you try to access (provided of course they do not exist yet). \n",
    "    # To create such a \"default\" item, it calls the function object that you pass in the constructor.\n",
    "    # inour case, the default item's value is an empty list\n",
    "    trn_anno = collections.defaultdict(lambda:[])\n",
    "    \n",
    "    # iterate through the IMAGES_ANNOTATIONS data structure...\n",
    "    for o in IMAGES_ANNOTATIONS:\n",
    "        # should we include that annotation ?\n",
    "        it_should_be_included = not o['ignore']\n",
    "        \n",
    "        # if so, then...\n",
    "        if it_should_be_included:\n",
    "            # append the bounding box and the id \n",
    "            bounding_box = o[BBOX]\n",
    "            \n",
    "            # we convert VOC's (x, y, height, width) format to (xmin, ymin, xmax, ymax)\n",
    "            # we also swap the order from (xmin, ymin, xmax, ymax) to (ymin, xmin, ymax, xmax)\n",
    "            # to be more in tune with numpy's orderings\n",
    "            x = bounding_box[0]\n",
    "            y = bounding_box[1]\n",
    "            width = bounding_box[2]\n",
    "            height = bounding_box[3]\n",
    "            \n",
    "            xmin = x\n",
    "            ymin = y\n",
    "            xmax = width + x - 1\n",
    "            ymax = height + y - 1\n",
    "            \n",
    "            rearranged_bounding_box = np.array([ymin, xmin, ymax, xmax])\n",
    "            \n",
    "            # the id of the image where the annotation is  and category id\n",
    "            img_id = o[IMG_ID]\n",
    "            cat_id = o[CAT_ID]\n",
    "            \n",
    "            # the full annotation data\n",
    "            annotation_data = (rearranged_bounding_box, cat_id)\n",
    "            \n",
    "            # add that annotation to the basket of annotations for the particular\n",
    "            # image\n",
    "            trn_anno[IMG_ID].append(annotation_data)\n",
    "    \n",
    "    return trn_anno\n",
    "\n",
    "trn_anno = create_key_annotation_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trn_anno)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
